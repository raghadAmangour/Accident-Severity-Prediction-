# -*- coding: utf-8 -*-
"""Automobile Accident Severity Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u-UlbxiQSM_0IQhk1y17M7BIVhSNj1vm

تمام، مشروع تعلُّم الآلة على بيانات **US Accidents** فكرة رائعة ومفيدة جدًا! 💪

أنا جاهز أساعدك خطوة خطوة من البداية للنهاية. خلينا نبدأ بالتخطيط العام للمشروع، وبعدها نبدأ التنفيذ معًا.

---

## خطة مشروع تعلُّم الآلة على بيانات US Accidents

### 1. **فهم البيانات واستكشافها (Exploratory Data Analysis - EDA)**

* قراءة البيانات
* فهم الأعمدة وأنواعها
* التعامل مع القيم المفقودة
* تحليل إحصائي للبيانات (وصفية)
* رسم بعض الرسوم البيانية للتوزيعات والعلاقات

### 2. **تحضير البيانات (Data Preprocessing)**

* تنظيف البيانات (حذف أو تعويض القيم الفارغة)
* تحويل البيانات النصية إلى أرقام (Encoding)
* إنشاء ميزات جديدة (Feature Engineering)
* تقليل حجم البيانات (لو كبير جدًا) للاختبار

### 3. **اختيار هدف المشروع (Target Variable)**

* مثلاً: التنبؤ بشدة الحادث (`Severity`) بناءً على العوامل الأخرى

### 4. **تقسيم البيانات (Train/Test Split)**

* تقسيم البيانات إلى مجموعات تدريب واختبار

### 5. **اختيار نموذج تعلُّم الآلة (Model Selection)**

* مثلاً: الانحدار اللوجستي، شجرة القرار، الغابات العشوائية، XGBoost...

### 6. **تدريب النموذج (Model Training)**

* تدريب النموذج على بيانات التدريب

### 7. **تقييم النموذج (Model Evaluation)**

* استخدام مقاييس مناسبة (مثل الدقة Accuracy، F1-score، recall، precision)
* اختبار النموذج على بيانات الاختبار

### 8. **تحسين النموذج (Model Tuning)**

* ضبط المعاملات (Hyperparameter tuning)
* تحسين الأداء

### 9. **النشر أو الاستخدام العملي**

* حفظ النموذج
* عمل تنبؤات على بيانات جديدة

---

## هل توافق على هذه الخطة؟

لو تحب، نبدأ فورًا بالخطوة الأولى: **قراءة البيانات وعرض بعض المعلومات الأساسية؟**

إذا نعم، أرسل لي فقط، وأنا أجهز لك كود Python وشرح لكل خطوة!
"""

from google.colab import files
files.upload()  # اختر ملف kaggle.json من جهازك

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d sobhanmoosavi/us-accidents
!unzip -q us-accidents.zip

!pip install tensorflow

import numpy as np
import pandas as pd

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

import tensorflow as tf

import pandas as pd

data = pd.read_csv('US_Accidents_March23.csv', nrows=400000)

data

print(data.head())

data.info()

data.describe()

"""## Data Cleaning & Preprocessing

###Missing Values
"""

data.isna().mean()

missing_ratio = data.isna().mean() # سيعرض نسبة القيم الناقصة فقط للأعمدة التي فيها قيم ناقصة، مرتبة تنازليًا.
print(missing_ratio[missing_ratio > 0].sort_values(ascending=False))

missing = data.isna().sum()
missing = missing[missing > 0]  # فقط الأعمدة التي تحتوي على قيم ناقصة
print(missing)

#الطريقة البسيطة لمعرفة الأعمدة التي تحتوي على قيم ناقصة:
#يُرجع عدد القيم الناقصة في كل عمود.

#أي عمود يكون له قيمة أكبر من 0 → يعني يحتوي على قيم ناقصة.

data.isna().sum()

'Number' in data.columns

null_columns = ['End_Lat', 'End_Lng', 'Wind_Chill(F)', 'Precipitation(in)']

data = data.drop(null_columns, axis=1)

data.isna().sum()

data = data.dropna(axis=0).reset_index(drop=True)

"""| الجزء                     | ماذا يفعل؟                                                                                         |
| ------------------------- | -------------------------------------------------------------------------------------------------- |
| `data.dropna(axis=0)`     | يحذف أي **صف** يحتوي على قيمة ناقصة (`NaN`).<br> `axis=0` تعني الصفوف.                             |
| `.reset_index(drop=True)` | يعيد ترقيم الصفوف من جديد بعد الحذف،<br> `drop=True` يعني عدم الاحتفاظ بالفهرس القديم كعمود إضافي. |
| `data = ...`              | يُعيد تخزين النتيجة في نفس متغير `data` (أي يُحدّث البيانات).                                      |

مثال مبسط:
لو عندك جدول بيانات مثل:

| Name  | Age | City   |
| ----- | --- | ------ |
| Ali   | 25  | Riyadh |
| Sarah | NaN | Jeddah |
| Ahmed | 30  | NaN    |

بعد تشغيل:

python
Copy
Edit
data = data.dropna(axis=0).reset_index(drop=True)
النتيجة ستكون:

| Name | Age | City   |
| ---- | --- | ------ |
| Ali  | 25  | Riyadh |


الصفان الثاني والثالث تم حذفهُما لأن فيهما قيم ناقصة.

الفهرسة تم إعادة ضبطها (0، 1، 2...)

⚠️ ملاحظة مهمة:


هذا السطر يحذف الصف بالكامل حتى لو كانت القيمة الناقصة في عمود واحد فقط.

لذا يجب استخدامه فقط بعد التأكد أنك لا تحتاج تلك الصفوف أو الأعمدة.
"""

print("Total missing values:", data.isna().sum().sum())

"""📌 ماذا يفعل هذا السطر؟
هو يقوم بطباعة العدد الإجمالي لجميع القيم الناقصة (missing values) في كامل جدول البيانات data.

| الجزء           | ماذا يفعل؟                                                                                         |
| --------------- | -------------------------------------------------------------------------------------------------- |
| `data.isna()`   | يُرجع جدول بنفس شكل `data` لكن القيم فيه تكون `True` إذا كانت `NaN`، و `False` إذا كانت غير ناقصة. |
| `.sum()`        | يجمع عدد القيم الناقصة **في كل عمود** (لأن `True` = 1 و `False` = 0 في بايثون).                    |
| `.sum()` الثاني | يجمع كل نتائج الأعمدة معًا، ليعطيك **العدد الكلي للقيم الناقصة** في كامل الجدول.                   |
| `print(...)`    | يطبع النتيجة على الشاشة مع النص التوضيحي `"Total missing values:"`.                                |
"""

data

import matplotlib.pyplot as plt
import seaborn as sns
sns.countplot(x='Severity', data=data)
plt.title('Distribution of Accident Severity')
plt.xlabel('Severity')
plt.ylabel('Count')
plt.show()

numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns

for col in numerical_cols:
    plt.figure(figsize=(6, 3))
    sns.histplot(data[col], kde=True, bins=30)
    plt.title(f'Distribution of {col}')
    plt.show()

plt.figure(figsize=(10, 5))
sns.boxplot(x='Severity', y='Distance(mi)', data=data)
plt.title('Distance vs Severity')
plt.show()

#plt.figure(figsize=(12, 10))
#sns.heatmap(data.corr(), annot=False, cmap='coolwarm')
#plt.title('Correlation Heatmap')
#plt.show()

"""#Unnecessary Columns"""

{column: len(data[column].unique()) for column in data.columns if data.dtypes[column] == 'object'}

"""الهدف:
إنشاء قاموس (dictionary) يحتوي على:

اسم كل عمود نصي (object)

وعدد القيم الفريدة (unique values) في هذا العمود

| الجزء                                | الشرح                                                                               |
| ------------------------------------ | ----------------------------------------------------------------------------------- |
| `for column in data.columns`         | حلقة تمر على كل عمود في جدول البيانات                                               |
| `if data.dtypes[column] == 'object'` | شرط: فقط الأعمدة التي نوع بياناتها نصية (`object`)                                  |
| `data[column].unique()`              | تُرجع جميع القيم الفريدة (المختلفة) في هذا العمود                                   |
| `len(...)`                           | لحساب عدد هذه القيم الفريدة                                                         |
| `{column: len(...)} `                | يبني زوج مفتاح وقيمة في القاموس، المفتاح هو اسم العمود والقيمة هي عدد القيم الفريدة |

مثال مبسط:
افترض أن عندك جدول بيانات كالتالي:

| City   | Weather |
| ------ | ------- |
| Riyadh | Sunny   |
| Jeddah | Cloudy  |
| Riyadh | Sunny   |
| Dammam | Rain    |

الكود سيُنتج:

{
  'City': 3,           # Riyadh, Jeddah, Dammam
  'Weather': 3         # Sunny, Cloudy, Rain
}

🛠️ لماذا هذا مفيد؟
يساعدك تعرف الأعمدة النصية وعدد الفئات (الفيمات) الموجودة فيها.

مهم جدًا قبل أي ترميز (Encoding)، مثل LabelEncoder أو OneHotEncoder.

إذا كان عدد القيم الفريدة كبير جدًا، ربما لا يناسب نموذجك.
"""

unneeded_columns = ['ID', 'Description', 'Street', 'City', 'Zipcode', 'Country']

data = data.drop(unneeded_columns, axis=1)

"""🎯 الهدف:
حذف الأعمدة غير المفيدة (أو غير الضرورية) من بياناتك قبل التدريب على نموذج التعلم الآلي.

📋 شرح سبب حذف كل عمود:

| العمود        | السبب المحتمل لحذفه                                        |
| ------------- | ---------------------------------------------------------- |
| `ID`          | رقم تعريف فريد لا يُفيد النموذج.                           |
| `Description` | نص طويل جدًا؛ قد يحتاج معالجة لغوية معقدة (NLP).           |
| `Street`      | تفاصيل دقيقة جدًا؛ قد لا تضيف فائدة تحليلية.               |
| `City`        | عدد المدن كبير جدًا → ترميزها صعب أو غير فعّال.            |
| `Zipcode`     | غالبًا مشابه للموقع الجغرافي الموجود في أعمدة أخرى.        |
| `Country`     | كلها "US" تقريبًا في هذه البيانات، فلا تضيف معلومات جديدة. |

🧪 مثال مصغر:
لو كان لديك جدول مثل هذا:

| ID   | Description     | City    | Severity |
| ---- | --------------- | ------- | -------- |
| A001 | Accident on I-5 | Seattle | 3        |
| A002 | Crash on 101    | LA      | 2        |

بعد الحذف:

| Severity |
| -------- |
| 3        |
| 2        |



(لو كان هناك أعمدة أخرى مثل Severity أو Start_Lat فهي تبقى، فقط الأعمدة غير المفيدة تُحذف.)
"""

data

def get_years(df, column):
    return df[column].apply(lambda date: date[0:4])

def get_months(df, column):
    return df[column].apply(lambda date: date[5:7])

"""🎯 الهدف:
استخراج السنة والشهر من عمود يحتوي على تواريخ (مثل Start_Time أو End_Time) وتخزينها في أعمدة جديدة.

🧠 شرح تفصيلي:
🟦 الدالة get_years(df, column)

| الجزء                      | المعنى                                                                                                |
| -------------------------- | ----------------------------------------------------------------------------------------------------- |
| `def get_years(...)`       | تعريف دالة اسمها `get_years`                                                                          |
| `df[column]`               | الوصول إلى عمود في جدول البيانات                                                                      |
| `.apply(lambda date: ...)` | تطبيق دالة لكل صف (لكل تاريخ)                                                                         |
| `date[0:4]`                | تقطع أول 4 أحرف من التاريخ → وهو الجزء الخاص بالسنة (مثلاً `"2019"` إذا التاريخ `"2019-05-01 14:00"`) |
| **النتيجة**                | عمود جديد يحتوي على السنة فقط من كل تاريخ.                                                            |

🟦 الدالة get_months(df, column)
مثل السابقة، لكنها تأخذ الأحرف من الموضع 5 إلى 7 → وهي تمثل الشهر.

'2020-11-18 08:00:00'[5:7]  →  '11'

⚠️ ملاحظة مهمة:
هذه الدوال تفترض أن التاريخ من نوع نصي (string)، وليس من نوع datetime.

إذا كان العمود من نوع datetime64, الأفضل استخدام:

df['Start_Time'].dt.year

df['Start_Time'].dt.month

🧪 مثال عملي:
إذا عندك:


df['Start_Time'] = ['2020-05-01 08:00:00', '2019-11-15 14:30:00']

وقمت بتطبيق:


df['Start_Year'] = get_years(df, 'Start_Time')

df['Start_Month'] = get_months(df, 'Start_Time')

النتيجة:

| Start\_Time         | Start\_Year | Start\_Month |
| ------------------- | ----------- | ------------ |
| 2020-05-01 08:00:00 | 2020        | 05           |
| 2019-11-15 14:30:00 | 2019        | 11           |
"""

data['Start_Time_Month'] = get_months(data, 'Start_Time')
data['Start_Time_Year'] = get_years(data, 'Start_Time')

data['End_Time_Month'] = get_months(data, 'End_Time')
data['End_Time_Year'] = get_years(data, 'End_Time')

data['Weather_Timestamp_Month'] = get_months(data, 'Weather_Timestamp')
data['Weather_Timestamp_Year'] = get_years(data, 'Weather_Timestamp')


data = data.drop(['Start_Time', 'End_Time', 'Weather_Timestamp'], axis=1)

"""أكيد! هذا الكود يوضح خطوة مهمة في معالجة البيانات وخاصة استخراج أجزاء من التواريخ ثم حذف الأعمدة الأصلية. دعني أشرح لك كل خطوة:

شرح كل جزء:
1. استخراج الشهر والسنة من عمود Start_Time:
python
Copy
Edit
data['Start_Time_Month'] = get_months(data, 'Start_Time')
data['Start_Time_Year'] = get_years(data, 'Start_Time')
get_months: تستخرج الشهر (مثلاً: "01" إلى "12") من تاريخ بداية الحادث.

get_years: تستخرج السنة (مثلاً: "2019" أو "2020") من تاريخ بداية الحادث.

النتيجة: عمودان جديدان Start_Time_Month و Start_Time_Year يحتويان على قيم شهر وسنة كل حادث.

2. استخراج الشهر والسنة من عمود End_Time:

data['End_Time_Month'] = get_months(data, 'End_Time')

data['End_Time_Year'] = get_years(data, 'End_Time')

نفس الخطوة لكن لتاريخ نهاية الحادث.

3. استخراج الشهر والسنة من عمود Weather_Timestamp:

data['Weather_Timestamp_Month'] = get_months(data, 'Weather_Timestamp')

data['Weather_Timestamp_Year'] = get_years(data, 'Weather_Timestamp')

تستخرج الشهر والسنة من توقيت الطقس المسجل.

4. حذف الأعمدة الأصلية للتاريخ:

data = data.drop(['Start_Time', 'End_Time', 'Weather_Timestamp'], axis=1)

بعد استخراج السنة والشهر من التواريخ، لم نعد بحاجة للأعمدة الأصلية.


نحذفها لتقليل التعقيد وحجم البيانات.

axis=1 تعني حذف أعمدة.

🧠 لماذا نفعل هذا؟
نماذج التعلم الآلي غالبًا لا تفهم التواريخ النصية أو المعقدة.

بتقسيم التاريخ إلى سنة وشهر، نعطي النموذج معلومات منظمة وأسهل للفهم.

حذف الأعمدة الأصلية يقلل من الضوضاء ويُسرع عملية التدريب.
"""

data

"""#Encoding"""

def onehot_encode(df, columns, prefixes):
    df = df.copy()
    for column, prefix in zip(columns, prefixes):
        dummies = pd.get_dummies(df[column], prefix=prefix)
        df = pd.concat([df, dummies], axis=1)
        df = df.drop(column, axis=1)
    return df

"""أكيد! هذا الكود يعرّف دالة مهمّة جدًا في مرحلة تجهيز البيانات للنماذج، وهي الترميز الأحادي (One-Hot Encoding).
دعني أشرح لك خطوة بخطوة:

🎯 الهدف من الدالة:

تحويل الأعمدة التي تحتوي على بيانات فئوية (Categorical) مثل "Day", "Weather", "State" إلى أعمدة رقمية باستخدام تقنية One-Hot Encoding.

🧠 شرح كل جزء:


| السطر                                           | الشرح                                                                                                                                                                                                                      |
| ----------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `def onehot_encode(df, columns, prefixes):`     | تعريف دالة اسمها `onehot_encode` تأخذ 3 مدخلات: <br>1. `df`: جدول البيانات <br>2. `columns`: قائمة بأسماء الأعمدة التي تريد ترميزها <br>3. `prefixes`: قائمة بنفس الطول تُستخدم لتسمية الأعمدة الجديدة الناتجة عن الترميز. |
| `df = df.copy()`                                | إنشاء نسخة من DataFrame الأصلي لتجنب تعديل البيانات الأصلية مباشرة.                                                                                                                                                        |
| `for column, prefix in zip(columns, prefixes):` | حلقة تمر على كل عمود مع البادئة الخاصة به، باستخدام `zip()` لربط العمود مع البادئة المناسبة.                                                                                                                               |
| `pd.get_dummies(df[column], prefix=prefix)`     | هذه الدالة من pandas تقوم بـ **one-hot encoding**: <br>تحوّل كل فئة داخل العمود إلى **عمود جديد يحتوي على 0 أو 1**.                                                                                                        |
| `pd.concat([df, dummies], axis=1)`              | دمج الأعمدة الجديدة الناتجة عن الترميز (`dummies`) مع DataFrame الأصلي.                                                                                                                                                    |
| `df = df.drop(column, axis=1)`                  | حذف العمود الأصلي بعد تحويله إلى أعمدة رقمية.                                                                                                                                                                              |
| `return df`                                     | تُرجع نسخة جديدة من DataFrame بعد الترميز.                                                                                                                                                                                 |

🧪 مثال عملي:
لو عندك DataFrame مثل:

| Color |
| ----- |
| Red   |
| Blue  |
| Red   |
| Green |

وقمت بتطبيق:

python
Copy
Edit
onehot_encode(df, ['Color'], ['Color'])

النتيجة ستكون:

| Color\_Blue | Color\_Green | Color\_Red |
| ----------- | ------------ | ---------- |
| 0           | 0            | 1          |
| 1           | 0            | 0          |
| 0           | 0            | 1          |
| 0           | 1            | 0          |

✅ لماذا نستخدم One-Hot Encoding؟
لأن خوارزميات التعلم الآلي لا تفهم القيم النصية.

تحويلها إلى أرقام يجعل النموذج قادرًا على التعامل معها بشكل صحيح.

One-hot هو الأكثر استخدامًا مع البيانات الفئوية غير المرتبة (مثل المدينة، الحالة الجوية...).
"""

{column: len(data[column].unique()) for column in data.columns if data.dtypes[column] == 'object'}

data = onehot_encode(
    data,
    columns=['County', 'State', 'Timezone', 'Airport_Code', 'Wind_Direction', 'Weather_Condition'],
    prefixes=['SI', 'CO', 'ST', 'TZ', 'AC', 'WD', 'WC']
)

data

def get_binary_column(df, column):
    if column == 'Source':
        return df[column].apply(lambda x: 1 if x == 'MapQuest' else 0)
    else:
        return df[column].apply(lambda x: 1 if x == 'Day' else 0)

"""ممتاز! هذا الكود يعرّف دالة اسمها get_binary_column، وهي تُستخدم لتحويل عمود فئوي (Categorical column) إلى عمود ثنائي (Binary column) — أي يحتوي فقط على 1 أو 0.

🎯 الهدف:
تحويل عمود فئوي إلى عمود ثنائي (binary) باستخدام قاعدة محددة:

إذا كان العمود هو 'Source'، سيتم ترميزه كـ:

1 إذا كانت القيمة 'MapQuest'

0 إذا كانت أي شيء آخر

أما إذا كان العمود ليس 'Source' (يعني أي عمود آخر)، سيتم ترميزه كـ:

1 إذا كانت القيمة 'Day'

0 إذا كانت أي شيء آخر

🧠 شرح تفصيلي لكل جزء:

| السطر                                                            | الشرح                                                                                        |
| ---------------------------------------------------------------- | -------------------------------------------------------------------------------------------- |
| `def get_binary_column(df, column):`                             | تعريف دالة اسمها `get_binary_column` تأخذ:<br>1️⃣ DataFrame `df`،<br>2️⃣ اسم العمود `column` |
| `if column == 'Source':`                                         | تحقق مما إذا كان العمود هو `'Source'`                                                        |
| `return df[column].apply(lambda x: 1 if x == 'MapQuest' else 0)` | إذا كان العمود هو `'Source'`، فحوّل القيم إلى `1` إذا كانت `'MapQuest'`، أو `0` غير ذلك      |
| `else:`                                                          | إذا كان العمود ليس `'Source'`                                                                |
| `return df[column].apply(lambda x: 1 if x == 'Day' else 0)`      | حوّل القيم إلى `1` إذا كانت `'Day'`، أو `0` غير ذلك                                          |

🧪 مثال عملي:

إذا كانت البيانات:

df = pd.DataFrame({'Source': ['MapQuest', 'Bing', 'MapQuest', 'Here']})


وقمت بتطبيق:


df['Source_binary'] = get_binary_column(df, 'Source')

ستحصل على:

| Source   | Source\_binary |
| -------- | -------------- |
| MapQuest | 1              |
| Bing     | 0              |
| MapQuest | 1              |
| Here     | 0              |

مثال آخر:

df = pd.DataFrame({'Sunrise_Sunset': ['Day', 'Night', 'Day', 'Night']})

df['Daytime'] = get_binary_column(df, 'Sunrise_Sunset')

النتيجة:

| Sunrise\_Sunset | Daytime |
| --------------- | ------- |
| Day             | 1       |
| Night           | 0       |
| Day             | 1       |
| Night           | 0       |

✅ لماذا نستخدم هذا النوع من الترميز؟
لأنه مفيد عند وجود قيمتين فقط (binary category).

يبسط البيانات لجعلها مناسبة لنماذج التعلم الآلي.
"""

data['Source'] = get_binary_column(data, 'Source')

data['Sunrise_Sunset'] = get_binary_column(data, 'Sunrise_Sunset')
data['Civil_Twilight'] = get_binary_column(data, 'Civil_Twilight')
data['Nautical_Twilight'] = get_binary_column(data, 'Nautical_Twilight')
data['Astronomical_Twilight'] = get_binary_column(data, 'Astronomical_Twilight')

"""رائع! 🎯 هذا الكود يُطبق الدالة get_binary_column() التي شرحناها سابقًا على عدة أعمدة من البيانات لتحويلها إلى قيم ثنائية (0 أو 1).

دعني أشرح لك سطرًا بسطر:

data['Source'] = get_binary_column(data, 'Source')


➤ ماذا يفعل؟

يحوّل عمود 'Source' إلى عمود جديد يحتوي فقط على 1 أو 0.


إذا كانت القيمة 'MapQuest' → تصبح 1، غير ذلك → 0.

data['Sunrise_Sunset'] = get_binary_column(data, 'Sunrise_Sunset')

data['Civil_Twilight'] = get_binary_column(data, 'Civil_Twilight')

data['Nautical_Twilight'] = get_binary_column(data, 'Nautical_Twilight')

data['Astronomical_Twilight'] = get_binary_column(data, 'Astronomical_Twilight')


➤ ماذا تفعل هذه الأسطر؟

تطبق نفس الفكرة على 4 أعمدة تتعلق بفترات الإضاءة في اليوم.


القيم التي كانت 'Day' تُحوَّل إلى 1، وغيرها (مثل 'Night') تتحول إلى 0.

🧠 الفكرة العامة:

| العمود                  | القيمة الأصلية | القيمة بعد التحويل |
| ----------------------- | -------------- | ------------------ |
| `Source`                | MapQuest       | 1                  |
|                         | Bing, Here...  | 0                  |
| `Sunrise_Sunset`        | Day            | 1                  |
|                         | Night          | 0                  |
| `Civil_Twilight`        | Day            | 1                  |
|                         | Night          | 0                  |
| `Nautical_Twilight`     | Day            | 1                  |
|                         | Night          | 0                  |
| `Astronomical_Twilight` | Day            | 1                  |
|                         | Night          | 0                  |

🎯 لماذا نفعل هذا؟
البيانات النصية لا تفهمها نماذج التعلم الآلي.

هذه الأعمدة تحتوي على قيمتين فقط → لذلك يمكننا استخدام الترميز الثنائي (Binary Encoding) بدلاً من One-Hot.

يجعل البيانات جاهزة للنماذج بدون الحاجة إلى معالجات إضافية.
"""

data

"""#Splitting/Scaling"""

y = data['Severity'].copy()

X = data.drop('Severity', axis=1).copy()

y.unique()

y = y - 1

X = X.astype(float)

scaler = StandardScaler()

X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=100)

X.shape

inputs = tf.keras.Input(shape=(X.shape[1],))
x = tf.keras.layers.Dense(64, activation='relu')(inputs)
x = tf.keras.layers.Dense(64, activation='relu')(x)
outputs = tf.keras.layers.Dense(4, activation='softmax')(x)

model = tf.keras.Model(inputs, outputs)

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
batch_size = 32
epochs = 20

history = model.fit(
    X_train,
    y_train,
    validation_split=0.2,
    batch_size=batch_size,
    epochs=epochs,
    callbacks=[
        tf.keras.callbacks.ReduceLROnPlateau(),
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=3,
            restore_best_weights=True
        )
    ]
)

print("Test Accuracy:", model.evaluate(X_test, y_test, verbose=0)[1])

